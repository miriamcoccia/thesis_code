{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_data():\n",
    "    # Read the data from ../data/raw/overall_filtered_us_data.csv\n",
    "    data = pd.read_csv('../data/raw/overall_filtered_us_data.csv', low_memory=False)\n",
    "\n",
    "    # Read the user ids from ../data/processed/combined_data.csv\n",
    "    user_ids = pd.read_csv('../data/processed/combined_data.csv')['user']\n",
    "\n",
    "    # Filter the data to only include rows with user ids present in combined_data.csv\n",
    "    data = data[data['unique_id'].isin(user_ids)]\n",
    "\n",
    "    # Read the question codes from ../data/raw/question_codes.json\n",
    "    question_codes = pd.read_json('../data/raw/question_codes.json')['code']\n",
    "    columns_to_keep = ['unique_id'] + list(question_codes)\n",
    "    data = data[columns_to_keep]\n",
    "\n",
    "    data.set_index('unique_id', inplace=True)\n",
    "    data.drop([\"F2A14\", 'F1A9_1', 'F1A13_1', 'F1A16_1', 'F2A8', 'F3A5_1'], axis=1, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "filtered_data = filter_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1A10_1</th>\n",
       "      <th>F2A6</th>\n",
       "      <th>F2A7</th>\n",
       "      <th>F2A9</th>\n",
       "      <th>F3A3_1</th>\n",
       "      <th>F3A6_1</th>\n",
       "      <th>F3A7_1</th>\n",
       "      <th>F3A8_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IDUS103408</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDUS103554</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDUS103826</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDUS104424</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDUS104578</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            F1A10_1  F2A6  F2A7  F2A9  F3A3_1  F3A6_1  F3A7_1  F3A8_1\n",
       "unique_id                                                            \n",
       "IDUS103408        2     3     3     2       6       4       4       7\n",
       "IDUS103554        7     5     2     5       7       1       1       1\n",
       "IDUS103826        4     1     1     4       7       1       3       4\n",
       "IDUS104424        5     4     3     4       7       1       2       2\n",
       "IDUS104578        6     5     2     4       6       1       3       2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.to_csv('../data/raw/filtered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def transform_data_with_question_codes(filtered_data_path, question_codes_path):\n",
    "    \"\"\"\n",
    "    Transforms the filtered data by replacing question codes with actual question text\n",
    "    and answer values with the corresponding answer text based on the question_codes.json file.\n",
    "\n",
    "    Parameters:\n",
    "    filtered_data_path (str): Path to the CSV file with the filtered data.\n",
    "    question_codes_path (str): Path to the question_codes.json file.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A transformed DataFrame with question text as column headers and answer text as values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the filtered data\n",
    "    filtered_data = pd.read_csv(filtered_data_path)\n",
    "\n",
    "    # Load the question_codes.json file\n",
    "    with open(question_codes_path) as f:\n",
    "        question_data = json.load(f)\n",
    "\n",
    "    # Create mappings for question codes to question text\n",
    "    code_to_question = {item['code']: item['question'] for item in question_data}\n",
    "\n",
    "    # Create mappings for each question's options\n",
    "    code_to_options = {item['code']: item['options'] for item in question_data}\n",
    "\n",
    "    # Step 1: Rename the columns using the question text\n",
    "    filtered_data.rename(columns=code_to_question, inplace=True)\n",
    "\n",
    "    # Step 2: Replace the values with the answer text\n",
    "    for code, options in code_to_options.items():\n",
    "        question_text = code_to_question.get(code)  # Get the question text mapped to this code\n",
    "        if question_text in filtered_data.columns:\n",
    "            # Convert numeric responses to strings before mapping\n",
    "            filtered_data[question_text] = filtered_data[question_text].astype(str).map(options)\n",
    "\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_path = '../data/raw/filtered_data.csv'\n",
    "question_codes_path = '../data/raw/question_codes.json'\n",
    "decoded_data = transform_data_with_question_codes(encoded_data_path, question_codes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Human Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>I feel like I am treated fairly by politicians.</th>\n",
       "      <th>To what degree does this concern you: The fact that the US is getting more deeply involved in the war in Ukraine</th>\n",
       "      <th>To what degree does this concern you: The situation of Ukrainian refugees in the US</th>\n",
       "      <th>To what degree does this concern you: The state of the US healthcare system</th>\n",
       "      <th>Agree or disagree: In the US, you can express your opinion publicly without fear of hostility</th>\n",
       "      <th>Agree or disagree: We no longer have room in the US for refugees from countries other than Ukraine</th>\n",
       "      <th>Agree or disagree: Foreigners exacerbate crime problems</th>\n",
       "      <th>Agree or disagree: Foreigners are taking jobs away from Americans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IDUS103408</td>\n",
       "      <td>Agree</td>\n",
       "      <td>moderately concerned</td>\n",
       "      <td>moderately concerned</td>\n",
       "      <td>not very concerned</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>Completely disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDUS103554</td>\n",
       "      <td>Completely disagree</td>\n",
       "      <td>very concerned</td>\n",
       "      <td>not very concerned</td>\n",
       "      <td>very concerned</td>\n",
       "      <td>Completely disagree</td>\n",
       "      <td>Completely agree</td>\n",
       "      <td>Completely agree</td>\n",
       "      <td>Completely agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IDUS103826</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>not concerned at all</td>\n",
       "      <td>not concerned at all</td>\n",
       "      <td>quite concerned</td>\n",
       "      <td>Completely disagree</td>\n",
       "      <td>Completely agree</td>\n",
       "      <td>Agree to some extent</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IDUS104424</td>\n",
       "      <td>Disagree to some extent</td>\n",
       "      <td>quite concerned</td>\n",
       "      <td>moderately concerned</td>\n",
       "      <td>quite concerned</td>\n",
       "      <td>Completely disagree</td>\n",
       "      <td>Completely agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDUS104578</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>very concerned</td>\n",
       "      <td>not very concerned</td>\n",
       "      <td>quite concerned</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Completely agree</td>\n",
       "      <td>Agree to some extent</td>\n",
       "      <td>Agree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id I feel like I am treated fairly by politicians.  \\\n",
       "0  IDUS103408                                           Agree   \n",
       "1  IDUS103554                             Completely disagree   \n",
       "2  IDUS103826                      Neither agree nor disagree   \n",
       "3  IDUS104424                         Disagree to some extent   \n",
       "4  IDUS104578                                        Disagree   \n",
       "\n",
       "  To what degree does this concern you: The fact that the US is getting more deeply involved in the war in Ukraine  \\\n",
       "0                               moderately concerned                                                                 \n",
       "1                                     very concerned                                                                 \n",
       "2                               not concerned at all                                                                 \n",
       "3                                    quite concerned                                                                 \n",
       "4                                     very concerned                                                                 \n",
       "\n",
       "  To what degree does this concern you: The situation of Ukrainian refugees in the US  \\\n",
       "0                               moderately concerned                                    \n",
       "1                                 not very concerned                                    \n",
       "2                               not concerned at all                                    \n",
       "3                               moderately concerned                                    \n",
       "4                                 not very concerned                                    \n",
       "\n",
       "  To what degree does this concern you: The state of the US healthcare system  \\\n",
       "0                                 not very concerned                            \n",
       "1                                     very concerned                            \n",
       "2                                    quite concerned                            \n",
       "3                                    quite concerned                            \n",
       "4                                    quite concerned                            \n",
       "\n",
       "  Agree or disagree: In the US, you can express your opinion publicly without fear of hostility  \\\n",
       "0                                           Disagree                                              \n",
       "1                                Completely disagree                                              \n",
       "2                                Completely disagree                                              \n",
       "3                                Completely disagree                                              \n",
       "4                                           Disagree                                              \n",
       "\n",
       "  Agree or disagree: We no longer have room in the US for refugees from countries other than Ukraine  \\\n",
       "0                         Neither agree nor disagree                                                   \n",
       "1                                   Completely agree                                                   \n",
       "2                                   Completely agree                                                   \n",
       "3                                   Completely agree                                                   \n",
       "4                                   Completely agree                                                   \n",
       "\n",
       "  Agree or disagree: Foreigners exacerbate crime problems  \\\n",
       "0                         Neither agree nor disagree        \n",
       "1                                   Completely agree        \n",
       "2                               Agree to some extent        \n",
       "3                                              Agree        \n",
       "4                               Agree to some extent        \n",
       "\n",
       "  Agree or disagree: Foreigners are taking jobs away from Americans  \n",
       "0                                Completely disagree                 \n",
       "1                                   Completely agree                 \n",
       "2                         Neither agree nor disagree                 \n",
       "3                                              Agree                 \n",
       "4                                              Agree                 "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Prompts For the LLMs \n",
    "(Based on the questions asked to the real people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompts_from_questions(question_codes_path):\n",
    "    \"\"\"\n",
    "    Generates prompt strings for each question and its corresponding options from the question_codes.json file,\n",
    "    excluding questions with specific codes.\n",
    "\n",
    "    Parameters:\n",
    "    question_codes_path (str): Path to the question_codes.json file.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of formatted prompts, each containing the question and its available options.\n",
    "    \"\"\"\n",
    "\n",
    "    # List of question codes to exclude\n",
    "    excluded_codes = [\"F2A14\", 'F1A9_1', 'F1A13_1', 'F1A16_1', 'F2A8', 'F3A5_1']\n",
    "\n",
    "    # Load the question_codes.json file\n",
    "    with open(question_codes_path) as f:\n",
    "        question_data = json.load(f)\n",
    "\n",
    "    prompts = []\n",
    "\n",
    "    # Loop over each question in the JSON data\n",
    "    for item in question_data:\n",
    "        question_code = item.get('code')  # Assuming each question has a 'code' key\n",
    "        question = item['question']\n",
    "        options = item['options']\n",
    "\n",
    "        # Skip questions whose codes are in the excluded list\n",
    "        if question_code in excluded_codes:\n",
    "            print(f\"Skipping question with code: {question_code}\")\n",
    "            continue\n",
    "\n",
    "        # Format the question and options as a readable string (no numbers involved)\n",
    "        prompt = f\"Based on your background and beliefs as described, respond to this question by selecting ONLY ONE of the provided options. Any answer not using exactly one of these options will be considered invalid.\\n**Question**: {question}\\n**Options** (choose ONE):\\n\"\n",
    "        for option_text in options.values():\n",
    "            prompt += f\"- {option_text}\\n\"\n",
    "\n",
    "        prompts.append(prompt.strip())  # Add the formatted prompt to the list\n",
    "\n",
    "    return prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping question with code: F1A9_1\n",
      "Skipping question with code: F1A13_1\n",
      "Skipping question with code: F1A16_1\n",
      "Skipping question with code: F2A8\n",
      "Skipping question with code: F2A14\n",
      "Skipping question with code: F3A5_1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Based on your background and beliefs as described, respond to this question by selecting ONLY ONE of the provided options. Any answer not using exactly one of these options will be considered invalid.\\n**Question**: I feel like I am treated fairly by politicians.\\n**Options** (choose ONE):\\n- Completely agree\\n- Agree\\n- Agree to some extent\\n- Neither agree nor disagree\\n- Disagree to some extent\\n- Disagree\\n- Completely disagree',\n",
       " 'Based on your background and beliefs as described, respond to this question by selecting ONLY ONE of the provided options. Any answer not using exactly one of these options will be considered invalid.\\n**Question**: To what degree does this concern you: The fact that the US is getting more deeply involved in the war in Ukraine\\n**Options** (choose ONE):\\n- not concerned at all\\n- not very concerned\\n- moderately concerned\\n- quite concerned\\n- very concerned',\n",
       " 'Based on your background and beliefs as described, respond to this question by selecting ONLY ONE of the provided options. Any answer not using exactly one of these options will be considered invalid.\\n**Question**: To what degree does this concern you: The situation of Ukrainian refugees in the US\\n**Options** (choose ONE):\\n- not concerned at all\\n- not very concerned\\n- moderately concerned\\n- quite concerned\\n- very concerned',\n",
       " 'Based on your background and beliefs as described, respond to this question by selecting ONLY ONE of the provided options. Any answer not using exactly one of these options will be considered invalid.\\n**Question**: To what degree does this concern you: The state of the US healthcare system\\n**Options** (choose ONE):\\n- not concerned at all\\n- not very concerned\\n- moderately concerned\\n- quite concerned\\n- very concerned',\n",
       " 'Based on your background and beliefs as described, respond to this question by selecting ONLY ONE of the provided options. Any answer not using exactly one of these options will be considered invalid.\\n**Question**: Agree or disagree: In the US, you can express your opinion publicly without fear of hostility\\n**Options** (choose ONE):\\n- Completely agree\\n- Agree\\n- Agree to some extent\\n- Neither agree nor disagree\\n- Disagree to some extent\\n- Disagree\\n- Completely disagree']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = generate_prompts_from_questions(question_codes_path)\n",
    "prompts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Responses (Before exposure to biased articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_responses_to_file(output_file, responses):\n",
    "    \"\"\"\n",
    "    Saves the list of responses to a JSON file.\n",
    "    If the file exists, it appends the new responses to the existing data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(output_file, 'r') as file:\n",
    "            existing_data = json.load(file)\n",
    "            responses = existing_data + responses\n",
    "    except FileNotFoundError:\n",
    "        pass  # If the file doesn't exist, we will create it later\n",
    "\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(responses, outfile, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "\n",
    "class CustomOutputParser:\n",
    "    def __init__(self):\n",
    "        # Combined list of all predefined options, sorted by length (longest first to avoid partial matches)\n",
    "        self.target_keys = sorted([\n",
    "            # Agreement options\n",
    "            'Completely agree', 'Agree', 'Agree to some extent', 'Neither agree nor disagree',\n",
    "            'Disagree to some extent', 'Disagree', 'Completely disagree',\n",
    "            # Concern levels\n",
    "            'not concerned at all', 'not very concerned', 'moderately concerned',\n",
    "            'quite concerned', 'very concerned'\n",
    "        ], key=len, reverse=True)  # Sort by length to prioritize longer options\n",
    "\n",
    "    def parse(self, output: str) -> dict:\n",
    "        try:\n",
    "            # Attempt to extract the exact option\n",
    "            selected_option = self.extract_option(output)\n",
    "            logging.debug(f\"Extracted option: {selected_option}\")\n",
    "\n",
    "            # Handle case when no valid option is found\n",
    "            if selected_option is None:\n",
    "                logging.warning(\"No valid option found in the output.\")\n",
    "                selected_option = \"N/A\"\n",
    "\n",
    "            return {\n",
    "                \"type\": \"final_answer\",\n",
    "                \"selected_option\": selected_option.strip()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error parsing LLM output: {e}\")\n",
    "            return {\"type\": \"raw_output\", \"content\": output.strip()}\n",
    "\n",
    "    def extract_option(self, text: str) -> str:\n",
    "        # Normalize the text (remove extra spaces, lowercase for comparison)\n",
    "        normalized_text = text.strip().lower()\n",
    "\n",
    "        # Check for exact matches of predefined options in the raw output\n",
    "        for option in self.target_keys:\n",
    "            # Use word boundaries to ensure we're matching the whole phrase\n",
    "            pattern = re.compile(r'\\b' + re.escape(option.lower()) + r'\\b')\n",
    "            if pattern.search(normalized_text):\n",
    "                return option  # Return the exact matched option\n",
    "\n",
    "        # No valid option found\n",
    "        return None\n",
    "\n",
    "# Ensure logging is set up to show debug information\n",
    "logging.basicConfig(level=logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from before_responses import load_persona_prompts\n",
    "from llm import CustomLLM\n",
    "\n",
    "def load_processed_responses(output_file):\n",
    "    \"\"\" Load the already processed responses from the file. \"\"\"\n",
    "    processed_responses = {}\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, 'r') as f:\n",
    "            try:\n",
    "                existing_data = json.load(f)\n",
    "                # Ensure the file contains a list of responses\n",
    "                if isinstance(existing_data, list):\n",
    "                    for response_data in existing_data:\n",
    "                        user_id = response_data.get('user_id')\n",
    "                        question = response_data.get('question')\n",
    "\n",
    "                        if user_id and question:\n",
    "                            if user_id not in processed_responses:\n",
    "                                processed_responses[user_id] = set()\n",
    "                            processed_responses[user_id].add(question)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}. Skipping invalid data in {output_file}.\")\n",
    "    \n",
    "    return processed_responses\n",
    "\n",
    "def append_responses_to_file(output_file, user_responses):\n",
    "    \"\"\" Append the user responses to the output file, ensuring correct JSON formatting. \"\"\"\n",
    "    if os.path.exists(output_file):\n",
    "        try:\n",
    "            with open(output_file, 'r+') as f:\n",
    "                try:\n",
    "                    existing_data = json.load(f)\n",
    "                    if not isinstance(existing_data, list):\n",
    "                        print(f\"Error: {output_file} contains invalid JSON format. Overwriting with new data.\")\n",
    "                        existing_data = []\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error: {output_file} contains invalid JSON. Overwriting with new data.\")\n",
    "                    existing_data = []\n",
    "                \n",
    "                # Append new responses to the existing data\n",
    "                existing_data.extend(user_responses)\n",
    "                \n",
    "                # Move file pointer to the beginning to overwrite\n",
    "                f.seek(0)\n",
    "                json.dump(existing_data, f, indent=4)\n",
    "                f.truncate()  # Ensure no leftover content\n",
    "        except IOError as e:\n",
    "            print(f\"Error writing to file {output_file}: {e}\")\n",
    "    else:\n",
    "        # If the file doesn't exist, create it and write the responses\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(user_responses, f, indent=4)\n",
    "\n",
    "def get_agents_responses():\n",
    "    # Load persona prompts\n",
    "    persona_prompts = load_persona_prompts('../data/processed/persona_prompts.json')\n",
    "\n",
    "    # Load the new question prompts\n",
    "    question_prompts = generate_prompts_from_questions('../data/raw/question_codes.json')\n",
    "\n",
    "    # Initialize the LLM and output parser\n",
    "    llm = CustomLLM(model=\"llama3.1:70b-instruct-q6_K\", api_url=\"https://inf.cl.uni-trier.de/\")\n",
    "    parser = CustomOutputParser()\n",
    "\n",
    "    # Load previously processed responses\n",
    "    output_file = '../data/processed/before_responses.json'\n",
    "    processed_responses = load_processed_responses(output_file)\n",
    "\n",
    "    # Iterate through persona prompts and new question prompts\n",
    "    for persona in persona_prompts:\n",
    "        persona_prompt = persona[\"persona_prompt\"]\n",
    "        user_id = persona[\"user_id\"]\n",
    "\n",
    "        # Check if the user has been processed before\n",
    "        if user_id not in processed_responses:\n",
    "            processed_responses[user_id] = set()\n",
    "\n",
    "        user_responses = []\n",
    "\n",
    "        for question_prompt in question_prompts:\n",
    "            # Skip if this user-question pair has already been processed\n",
    "            if question_prompt in processed_responses[user_id]:\n",
    "                print(f\"Skipping already processed User ID: {user_id}, Question: {question_prompt}\")\n",
    "                continue\n",
    "\n",
    "            # Send persona prompt and question prompt to LLM\n",
    "            response = llm.generate_response(persona_prompt, question_prompt)\n",
    "            parsed_output = parser.parse(response)\n",
    "            \n",
    "            # Output the raw and parsed response for inspection\n",
    "            print(f\"User ID: {user_id}\")\n",
    "            print(\"Raw output:\")\n",
    "            print(response)\n",
    "            print(\"Parsed output:\")\n",
    "            print(parsed_output)\n",
    "\n",
    "            # Collect the responses for the current user\n",
    "            user_responses.append({\n",
    "                \"user_id\": user_id,\n",
    "                \"question\": question_prompt,\n",
    "                \"response\": parsed_output\n",
    "            })\n",
    "            # Mark this question as processed for this user\n",
    "            processed_responses[user_id].add(question_prompt)\n",
    "        \n",
    "        # Append the user responses to the file after each user is processed\n",
    "        append_responses_to_file(output_file, user_responses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_agents_responses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Save Before Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total LLM responses loaded: 936\n",
      "[{'user_id': 'IDUS103408', 'question': 'Based on your background and beliefs as described, respond to this question by selecting ONLY ONE of the provided options. Any answer not using exactly one of these options will be considered invalid.\\n**Question**: I feel like I am treated fairly by politicians.\\n**Options** (choose ONE):\\n- Completely agree\\n- Agree\\n- Agree to some extent\\n- Neither agree nor disagree\\n- Disagree to some extent\\n- Disagree\\n- Completely disagree', 'response': {'type': 'final_answer', 'selected_option': 'Completely disagree'}}, {'user_id': 'IDUS103408', 'question': 'Based on your background and beliefs as described, respond to this question by selecting ONLY ONE of the provided options. Any answer not using exactly one of these options will be considered invalid.\\n**Question**: To what degree does this concern you: The fact that the US is getting more deeply involved in the war in Ukraine\\n**Options** (choose ONE):\\n- not concerned at all\\n- not very concerned\\n- moderately concerned\\n- quite concerned\\n- very concerned', 'response': {'type': 'final_answer', 'selected_option': 'quite concerned'}}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the LLM responses from the file\n",
    "llm_responses_path = '../data/processed/before_responses.json'  # Update with the correct path\n",
    "\n",
    "with open(llm_responses_path, 'r', encoding=\"utf-8\") as f:\n",
    "    llm_responses = json.load(f)  # Load the entire file as a JSON array\n",
    "\n",
    "# Check if the LLM responses loaded correctly\n",
    "print(f\"Total LLM responses loaded: {len(llm_responses)}\")\n",
    "print(llm_responses[:2])  # Display the first two responses to inspect the structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total question mappings loaded: 14\n",
      "[{'code': 'F1A9_1', 'question': 'I feel very angry when I think about the current situation.', 'options': {'1': 'Completely agree', '2': 'Agree', '3': 'Agree to some extent', '4': 'Neither agree nor disagree', '5': 'Disagree to some extent', '6': 'Disagree', '7': 'Completely disagree'}}, {'code': 'F1A10_1', 'question': 'I feel like I am treated fairly by politicians.', 'options': {'1': 'Completely agree', '2': 'Agree', '3': 'Agree to some extent', '4': 'Neither agree nor disagree', '5': 'Disagree to some extent', '6': 'Disagree', '7': 'Completely disagree'}}]\n"
     ]
    }
   ],
   "source": [
    "# Load the question codes JSON file\n",
    "question_code_map_path = '../data/raw/question_codes.json'  # Update with the correct path\n",
    "with open(question_code_map_path, 'r') as f:\n",
    "    question_code_map = json.load(f)\n",
    "\n",
    "# Check the structure of the question_code_map\n",
    "print(f\"Total question mappings loaded: {len(question_code_map)}\")\n",
    "print(question_code_map[:2])  # Display the first two mappings to inspect the structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode LLMs Before Responses to their code for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to extract the actual question from the LLM's full question text\n",
    "def extract_question_from_llm_text(llm_question_text):\n",
    "    # Use regex to capture the text after '**Question**:'\n",
    "    match = re.search(r'\\*\\*Question\\*\\*: (.+?)\\n', llm_question_text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_llm_response_to_code(question_code, response_text):\n",
    "    \"\"\"\n",
    "    Maps the LLM's textual response to the corresponding code based on the question code.\n",
    "    \"\"\"\n",
    "    # Iterate through the list to find the matching question_code\n",
    "    for entry in question_code_map:\n",
    "        if entry['code'] == question_code:\n",
    "            options = entry.get('options', {})  # Safely get options if available\n",
    "            for code, option in options.items():\n",
    "                if option.lower() == response_text.lower():\n",
    "                    return int(code)\n",
    "    return None  # Return None if no matching code is found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            F1A10_1  F2A6  F2A7  F2A9  F3A3_1  F3A6_1  F3A7_1  F3A8_1\n",
      "unique_id                                                            \n",
      "IDUS103408        2     3     3     2       6       4       4       7\n",
      "IDUS103554        7     5     2     5       7       1       1       1\n",
      "IDUS103826        4     1     1     4       7       1       3       4\n",
      "IDUS104424        5     4     3     4       7       1       2       2\n",
      "IDUS104578        6     5     2     4       6       1       3       2\n"
     ]
    }
   ],
   "source": [
    "print(filtered_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map LLM responses to numeric codes\n",
    "llm_responses_mapped = []\n",
    "for response in llm_responses:\n",
    "    extracted_question = extract_question_from_llm_text(response[\"question\"])\n",
    "    if not extracted_question:\n",
    "        continue\n",
    "\n",
    "    matched = False\n",
    "    for entry in question_code_map:\n",
    "        if extracted_question.lower() == entry['question'].lower():  # Compare case-insensitively\n",
    "            question_code = entry['code']\n",
    "            matched = True\n",
    "            break\n",
    "     \n",
    "    #if matched:\n",
    "\n",
    "        #print(f\"Matched question: {extracted_question} with code: {question_code}\")  # Debug print\n",
    "    #else:\n",
    "        #print(f\"No match found for question: {extracted_question}\")  # Debug print\n",
    "\n",
    "    # Map the LLM's response to a numeric code\n",
    "    mapped_code = map_llm_response_to_code(question_code, response['response']['selected_option'])\n",
    "    if mapped_code is not None:\n",
    "        llm_responses_mapped.append({\n",
    "            'user_id': response['user_id'],\n",
    "            'question_code': question_code,\n",
    "            'llm_response_code': mapped_code\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_llm_response_to_code(question_code, response_text):\n",
    "    for entry in question_code_map:\n",
    "        if entry['code'] == question_code:\n",
    "            options = entry.get('options', {})\n",
    "            for code, option in options.items():\n",
    "                if option.lower() == response_text.lower():\n",
    "                    #print(f\"Mapped response '{response_text}' to code: {code}\")  # Debug print\n",
    "                    return int(code)\n",
    "    print(f\"Failed to map response '{response_text}' for question code: {question_code}\")  # Debug print\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_code = map_llm_response_to_code(question_code, response['response']['selected_option'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining mapped questions and Mapped answer codes\n",
    "Both questions and answers are now mapped back to their codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total mapped responses: 936\n",
      "[{'user_id': 'IDUS103408', 'question_code': 'F1A10_1', 'llm_response_code': 7}, {'user_id': 'IDUS103408', 'question_code': 'F2A6', 'llm_response_code': 4}, {'user_id': 'IDUS103408', 'question_code': 'F2A7', 'llm_response_code': 1}, {'user_id': 'IDUS103408', 'question_code': 'F2A9', 'llm_response_code': 2}, {'user_id': 'IDUS103408', 'question_code': 'F3A3_1', 'llm_response_code': 1}]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store all mapped responses from LLM\n",
    "llm_responses_mapped = []\n",
    "\n",
    "# Iterate through all LLM responses\n",
    "for response in llm_responses:\n",
    "    user_id = response['user_id']  # Each user will have their own unique ID\n",
    "    extracted_question = extract_question_from_llm_text(response[\"question\"])  # Extract the question from the LLM response\n",
    "    \n",
    "    if not extracted_question:\n",
    "        continue  # Skip if question extraction failed\n",
    "\n",
    "    matched = False  # Track if we successfully matched the question\n",
    "    for entry in question_code_map:\n",
    "        if extracted_question.lower() == entry['question'].lower():\n",
    "            question_code = entry['code']  # Get the code for the matched question\n",
    "            matched = True\n",
    "            break\n",
    "    \n",
    "    # If a matching question is found, map the LLM's response to a numeric code\n",
    "    if matched:\n",
    "        #print(f\"Matched question: {extracted_question} with code: {question_code}\")\n",
    "\n",
    "        # Map the LLM's response to a numeric code based on the options in question_code_map\n",
    "        mapped_code = map_llm_response_to_code(question_code, response['response']['selected_option'].strip())\n",
    "\n",
    "        if mapped_code is not None:\n",
    "            # Store the mapped response with the user ID and question code\n",
    "            llm_responses_mapped.append({\n",
    "                'user_id': user_id,  # Include user ID for each response\n",
    "                'question_code': question_code,\n",
    "                'llm_response_code': mapped_code\n",
    "            })\n",
    "            #print(f\"Mapped response '{response['response']['selected_option']}' to code: {mapped_code} for user: {user_id}\")\n",
    "        else:\n",
    "            print(f\"Failed to map LLM response: '{response['response']['selected_option']}' for question: {question_code} and user: {user_id}\")\n",
    "    else:\n",
    "        #print(f\"No match found for extracted question: {extracted_question}\")\n",
    "        continue\n",
    "\n",
    "# Print total mapped responses and some of the mapped responses for verification\n",
    "print(f\"\\nTotal mapped responses: {len(llm_responses_mapped)}\")\n",
    "print(llm_responses_mapped[:5])  # Print the first 5 mapped responses to verify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the LLM (Before) Responses with the Actual Human Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_difference(real_response_code, llm_response_code, weight=1):\n",
    "    \"\"\"\n",
    "    Calculates the weighted difference between real and LLM response codes.\n",
    "    \n",
    "    Parameters:\n",
    "    - real_response_code: The real response code (numeric or categorical).\n",
    "    - llm_response_code: The response code generated by the LLM (numeric or categorical).\n",
    "    - weight: A scaling factor for the difference. Defaults to 1 (no weighting).\n",
    "    \n",
    "    Returns:\n",
    "    - The weighted difference between the real and LLM response codes.\n",
    "    \"\"\"\n",
    "    # Ensure the codes are comparable by converting them to float (if they are numeric)\n",
    "    try:\n",
    "        real_response_code = float(real_response_code)\n",
    "        llm_response_code = float(llm_response_code)\n",
    "    except ValueError:\n",
    "        # If not numeric, calculate difference as 1 if codes are different, 0 if the same\n",
    "        return weight if real_response_code != llm_response_code else 0\n",
    "    \n",
    "    # Calculate the absolute difference between the codes, weighted by the provided factor\n",
    "    difference = abs(real_response_code - llm_response_code)\n",
    "    return difference * weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id question_code  llm_response_code  real_response_code  difference\n",
      "0  IDUS103408       F1A10_1                  7                   2         5.0\n",
      "1  IDUS103408          F2A6                  4                   3         1.0\n",
      "2  IDUS103408          F2A7                  1                   3         2.0\n",
      "3  IDUS103408          F2A9                  2                   2         0.0\n",
      "4  IDUS103408        F3A3_1                  1                   6         5.0\n",
      "Average weighted difference between LLM and real responses: 1.7297008547008548\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def weighted_difference(real_response_code, llm_response_code, weight=1):\n",
    "    \"\"\"\n",
    "    Calculates the weighted difference between real and LLM response codes.\n",
    "    \n",
    "    Parameters:\n",
    "    - real_response_code: The real response code (numeric or categorical).\n",
    "    - llm_response_code: The response code generated by the LLM (numeric or categorical).\n",
    "    - weight: A scaling factor for the difference. Defaults to 1 (no weighting).\n",
    "    \n",
    "    Returns:\n",
    "    - The weighted difference between the real and LLM response codes.\n",
    "    \"\"\"\n",
    "    # Ensure the codes are comparable by converting them to float (if they are numeric)\n",
    "    try:\n",
    "        real_response_code = float(real_response_code)\n",
    "        llm_response_code = float(llm_response_code)\n",
    "    except ValueError:\n",
    "        # If not numeric, calculate difference as 1 if codes are different, 0 if the same\n",
    "        return weight if real_response_code != llm_response_code else 0\n",
    "    \n",
    "    # Calculate the absolute difference between the codes, weighted by the provided factor\n",
    "    difference = abs(real_response_code - llm_response_code)\n",
    "    return difference * weight\n",
    "\n",
    "def compare_llm_to_real(llm_responses_mapped, filtered_data):\n",
    "    \"\"\"\n",
    "    Compare LLM responses to real responses and calculate the weighted differences.\n",
    "\n",
    "    Parameters:\n",
    "    - llm_responses_mapped (list): A list of LLM response dictionaries, where each dictionary contains\n",
    "                                   'user_id', 'question_code', and 'llm_response_code'.\n",
    "    - filtered_data (DataFrame): A pandas DataFrame containing real responses, with user_id as the index\n",
    "                                 and question_code as the columns.\n",
    "\n",
    "    Returns:\n",
    "    - comparison_df (DataFrame): A pandas DataFrame containing the comparison results.\n",
    "    - average_weighted_difference (float): The average weighted difference between LLM and real responses.\n",
    "    \"\"\"\n",
    "    llm_vs_real_comparison = []\n",
    "\n",
    "    # Iterate through the LLM responses\n",
    "    for llm_response in llm_responses_mapped:\n",
    "        user_id = llm_response['user_id']\n",
    "        question_code = llm_response['question_code']\n",
    "        llm_response_code = llm_response['llm_response_code']\n",
    "        \n",
    "        # Check if the user_id and question_code exist in filtered_data\n",
    "        if user_id in filtered_data.index and question_code in filtered_data.columns:\n",
    "            # Fetch the real response\n",
    "            real_response = filtered_data.loc[user_id, question_code]\n",
    "            \n",
    "            # If real_response is a Series (multiple values), extract the first valid value\n",
    "            if isinstance(real_response, pd.Series):\n",
    "                real_response_code = real_response.iloc[0]  # Get the first value\n",
    "            else:\n",
    "                real_response_code = real_response\n",
    "            \n",
    "            # Check if the real response code is valid (not NaN)\n",
    "            if pd.notna(real_response_code):\n",
    "                # Calculate the weighted difference using the custom function\n",
    "                difference = weighted_difference(real_response_code, llm_response_code)\n",
    "                \n",
    "                # Store the comparison\n",
    "                llm_vs_real_comparison.append({\n",
    "                    'user_id': user_id,\n",
    "                    'question_code': question_code,\n",
    "                    'llm_response_code': llm_response_code,\n",
    "                    'real_response_code': real_response_code,\n",
    "                    'difference': difference\n",
    "                })\n",
    "\n",
    "    # Convert the comparison results to a DataFrame for analysis\n",
    "    comparison_df = pd.DataFrame(llm_vs_real_comparison)\n",
    "\n",
    "    # Calculate the average weighted difference\n",
    "    if not comparison_df.empty:\n",
    "        average_weighted_difference = comparison_df['difference'].mean()\n",
    "    else:\n",
    "        average_weighted_difference = None  # Handle the case where there's no valid comparison\n",
    "\n",
    "    return comparison_df, average_weighted_difference\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "\n",
    "# llm_responses_mapped = [ ... ] # Your list of LLM responses mapped\n",
    "# filtered_data = pd.DataFrame(...)  # Your filtered real data in a DataFrame\n",
    "\n",
    "# Call the function\n",
    "comparison_df, avg_difference = compare_llm_to_real(llm_responses_mapped, filtered_data)\n",
    "\n",
    "# Display results\n",
    "print(comparison_df.head())\n",
    "print(f\"Average weighted difference between LLM and real responses: {avg_difference}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F1A10_1', 'F2A6', 'F2A7', 'F2A9', 'F3A3_1', 'F3A6_1', 'F3A7_1',\n",
       "       'F3A8_1'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df.question_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib:matplotlib data path: c:\\Users\\miria\\Desktop\\ThesisProject\\venv\\lib\\site-packages\\matplotlib\\mpl-data\n",
      "DEBUG:matplotlib:CONFIGDIR=C:\\Users\\miria\\.matplotlib\n",
      "DEBUG:matplotlib:interactive is False\n",
      "DEBUG:matplotlib:platform is win32\n",
      "DEBUG:matplotlib:CACHEDIR=C:\\Users\\miria\\.matplotlib\n",
      "DEBUG:matplotlib.font_manager:Using fontManager instance from C:\\Users\\miria\\.matplotlib\\fontlist-v390.json\n",
      "C:\\Users\\miria\\AppData\\Local\\Temp\\ipykernel_11404\\2051577155.py:11: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x='difference', data=comparison_df, palette='coolwarm')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import matplotlib\n",
    "\n",
    "# Set Matplotlib's logging level to warning to avoid debug messages\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "\n",
    "# Plot distribution of differences\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='difference', data=comparison_df, palette='coolwarm')\n",
    "plt.title('Distribution of Differences between LLM and Real Responses', fontsize=14)\n",
    "plt.xlabel('Difference', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How far away are the LLM responses from the real responses (By question)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miria\\AppData\\Local\\Temp\\ipykernel_11404\\2031427725.py:6: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='question_code', y='difference', data=question_differences, palette='viridis')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the average difference per question\n",
    "question_differences = comparison_df.groupby('question_code')['difference'].mean().reset_index()\n",
    "\n",
    "# Plot average difference per question\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='question_code', y='difference', data=question_differences, palette='viridis')\n",
    "plt.title('Average Difference per Question', fontsize=14)\n",
    "plt.xlabel('Question Code', fontsize=12)\n",
    "plt.ylabel('Average Difference', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate the x-axis labels for readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS NEEDS TO BE CHANGED SINCE SUBJECTIVE QUESTIONS ARE DROPPED AT THE BEGINNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Alignment between LLMs and Humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "\n",
    "def categorize_response(response_code, question_code):\n",
    "    \"\"\"\n",
    "    Categorizes the response based on the question type.\n",
    "    \n",
    "    Args:\n",
    "    - response_code (int): The response code given by the LLM or real person.\n",
    "    - question_code (str): The identifier of the question to determine the categorization strategy.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The category ('Positive', 'Neutral', 'Negative', or 'Unknown').\n",
    "    \"\"\"\n",
    "\n",
    "    if question_code.startswith(\"F2\"):  # Questions with codes ranging from 1-5\n",
    "        if response_code in [1, 2]:  # Not concerned at all, Not very concerned\n",
    "            return 'Low Concern'\n",
    "        elif response_code in [3]:  # Moderately concerned\n",
    "            return 'Moderate Concern'\n",
    "        elif response_code in [4, 5]:  # Quite concerned, Very concerned\n",
    "            return 'High Concern'\n",
    "    else:  # Questions with codes ranging from 1-7\n",
    "        if response_code in [1, 2]:  # Completely agree, Agree\n",
    "            return 'Positive'\n",
    "        elif response_code in [3, 4, 5]:  # Neutral (Agree to some extent, Neither agree nor disagree)\n",
    "            return 'Neutral'\n",
    "        elif response_code in [6, 7]:  # Disagree to some extent, Disagree, Completely disagree\n",
    "            return 'Negative'\n",
    "    \n",
    "    return 'Unknown'\n",
    "\n",
    "def evaluate_llm_alignment(comparison_df, acceptable_difference_threshold=2):\n",
    "    \"\"\"\n",
    "    Evaluates the alignment between LLM responses and real people's responses using various metrics.\n",
    "    \n",
    "    Args:\n",
    "    - comparison_df (pd.DataFrame): DataFrame containing 'llm_response_code', 'real_response_code', 'difference', and 'question_code'.\n",
    "    - acceptable_difference_threshold (int): Threshold for \"close enough\" accuracy (default is 2).\n",
    "    \n",
    "    Outputs a summary of metrics and their interpretation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate Exact Match Accuracy\n",
    "    exact_match_accuracy = (comparison_df['llm_response_code'] == comparison_df['real_response_code']).mean() * 100\n",
    "    \n",
    "    # Calculate \"Close Enough\" Accuracy\n",
    "    close_enough_accuracy = (comparison_df['difference'] <= acceptable_difference_threshold).mean() * 100\n",
    "    \n",
    "    # Calculate Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(comparison_df['real_response_code'], comparison_df['llm_response_code'])\n",
    "    \n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(comparison_df['real_response_code'], comparison_df['llm_response_code'])\n",
    "    \n",
    "    # Apply categorization based on question type\n",
    "    comparison_df = comparison_df.copy()\n",
    "    comparison_df['real_response_category'] = comparison_df.apply(lambda row: categorize_response(row['real_response_code'], row['question_code']), axis=1)\n",
    "    comparison_df['llm_response_category'] = comparison_df.apply(lambda row: categorize_response(row['llm_response_code'], row['question_code']), axis=1)\n",
    "    \n",
    "    # Calculate categorical accuracy\n",
    "    categorical_accuracy = (comparison_df['real_response_category'] == comparison_df['llm_response_category']).mean() * 100\n",
    "    \n",
    "    # Print the metrics with interpretations\n",
    "    print(\"---- LLM Alignment Evaluation ----\")\n",
    "    print(f\"Exact Match Accuracy: {exact_match_accuracy:.2f}%\")\n",
    "    print(\"Interpretation: The LLM exactly matches real people's responses. Higher is desirable.\")\n",
    "    \n",
    "    print(f\"'Close Enough' Accuracy (within {acceptable_difference_threshold} steps): {close_enough_accuracy:.2f}%\")\n",
    "    print(\"Interpretation: The LLM response is close (within the defined step range) to real people's responses.\")\n",
    "    \n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(\"Interpretation: A high MSE indicates some large mismatches between LLM and real people's responses.\")\n",
    "    \n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"Interpretation: On average, LLM responses are about {mae:.2f} steps away from real people's responses.\")\n",
    "    \n",
    "    print(f\"Categorical Accuracy: {categorical_accuracy:.2f}%\")\n",
    "    print(\"Interpretation: The LLM matches the general sentiment (positive, neutral, negative, or concern level) about this percentage of the time.\")\n",
    "    \n",
    "    print(\"-----------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- LLM Alignment Evaluation ----\n",
      "Exact Match Accuracy: 24.68%\n",
      "Interpretation: The LLM exactly matches real people's responses. Higher is desirable.\n",
      "'Close Enough' Accuracy (within 2 steps): 72.22%\n",
      "Interpretation: The LLM response is close (within the defined step range) to real people's responses.\n",
      "Mean Squared Error (MSE): 5.29\n",
      "Interpretation: A high MSE indicates some large mismatches between LLM and real people's responses.\n",
      "Mean Absolute Error (MAE): 1.73\n",
      "Interpretation: On average, LLM responses are about 1.73 steps away from real people's responses.\n",
      "Categorical Accuracy: 41.77%\n",
      "Interpretation: The LLM matches the general sentiment (positive, neutral, negative, or concern level) about this percentage of the time.\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluate_llm_alignment(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Person MAE: 1.57\n",
      "Random Person MSE: 4.43\n",
      "Average Response MAE: 0.43\n",
      "Average Response MSE: 0.71\n",
      "Most Frequent Response MAE: 0.43\n",
      "Most Frequent Response MSE: 0.71\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def categorize_response(response_code, question_code):\n",
    "    if question_code.startswith(\"F2\"):  # Questions with codes ranging from 1-5\n",
    "        if response_code in [1, 2]:  # Not concerned at all, Not very concerned\n",
    "            return 'Low Concern'\n",
    "        elif response_code in [3]:  # Moderately concerned\n",
    "            return 'Moderate Concern'\n",
    "        elif response_code in [4, 5]:  # Quite concerned, Very concerned\n",
    "            return 'High Concern'\n",
    "    else:  # Questions with codes ranging from 1-7\n",
    "        if response_code in [1, 2]:  # Completely agree, Agree\n",
    "            return 'Positive'\n",
    "        elif response_code in [3, 4, 5]:  # Neutral (Agree to some extent, Neither agree nor disagree)\n",
    "            return 'Neutral'\n",
    "        elif response_code in [6, 7]:  # Disagree to some extent, Disagree, Completely disagree\n",
    "            return 'Negative'\n",
    "    \n",
    "    return 'Unknown'\n",
    "\n",
    "def calculate_baseline_errors(comparison_df):\n",
    "    \"\"\"\n",
    "    Calculates baseline errors for comparison with LLM responses using categorized responses.\n",
    "    \n",
    "    Args:\n",
    "    - comparison_df (pd.DataFrame): DataFrame containing 'llm_response_code', 'real_response_code', and 'question_code'.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Baseline MAE and MSE for random person, average response, and most frequent response.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure only the relevant question codes are considered\n",
    "    valid_question_codes = ['F1A10_1', 'F2A6', 'F2A7', 'F2A9', 'F3A3_1', 'F3A6_1', 'F3A7_1', 'F3A8_1']\n",
    "    comparison_df = comparison_df[comparison_df['question_code'].isin(valid_question_codes)]\n",
    "    \n",
    "    # Apply categorization\n",
    "    comparison_df['real_response_category'] = comparison_df.apply(\n",
    "        lambda row: categorize_response(row['real_response_code'], row['question_code']),\n",
    "        axis=1\n",
    "    )\n",
    "    comparison_df['llm_response_category'] = comparison_df.apply(\n",
    "        lambda row: categorize_response(row['llm_response_code'], row['question_code']),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Initialize a dictionary to store baseline results\n",
    "    baseline_results = {}\n",
    "    \n",
    "    # 1. Baseline with Random Person's Response\n",
    "    random_person_response = comparison_df.sample(1)\n",
    "    baseline_random_mae = np.mean(\n",
    "        np.abs(comparison_df['llm_response_code'] - random_person_response['real_response_code'].values[0])\n",
    "    )\n",
    "    baseline_random_mse = np.mean(\n",
    "        (comparison_df['llm_response_code'] - random_person_response['real_response_code'].values[0]) ** 2\n",
    "    )\n",
    "    baseline_results['Random Person MAE'] = baseline_random_mae\n",
    "    baseline_results['Random Person MSE'] = baseline_random_mse\n",
    "    \n",
    "    # 2. Baseline with Average Response\n",
    "    average_responses = comparison_df.groupby('question_code')['real_response_code'].mean()\n",
    "    comparison_df['average_response'] = comparison_df['question_code'].map(average_responses)\n",
    "    baseline_average_mae = np.mean(\n",
    "        np.abs(comparison_df['llm_response_code'] - comparison_df['average_response'])\n",
    "    )\n",
    "    baseline_average_mse = np.mean(\n",
    "        (comparison_df['llm_response_code'] - comparison_df['average_response']) ** 2\n",
    "    )\n",
    "    baseline_results['Average Response MAE'] = baseline_average_mae\n",
    "    baseline_results['Average Response MSE'] = baseline_average_mse\n",
    "    \n",
    "    # 3. Baseline with Most Frequent Response\n",
    "    most_frequent_responses = comparison_df.groupby('question_code')['real_response_code'].agg(lambda x: x.mode()[0])\n",
    "    comparison_df['most_frequent_response'] = comparison_df['question_code'].map(most_frequent_responses)\n",
    "    baseline_frequent_mae = np.mean(\n",
    "        np.abs(comparison_df['llm_response_code'] - comparison_df['most_frequent_response'])\n",
    "    )\n",
    "    baseline_frequent_mse = np.mean(\n",
    "        (comparison_df['llm_response_code'] - comparison_df['most_frequent_response']) ** 2\n",
    "    )\n",
    "    baseline_results['Most Frequent Response MAE'] = baseline_frequent_mae\n",
    "    baseline_results['Most Frequent Response MSE'] = baseline_frequent_mse\n",
    "    \n",
    "    return baseline_results\n",
    "\n",
    "# Example usage\n",
    "comparison_df = pd.DataFrame({\n",
    "    'llm_response_code': [1, 2, 3, 4, 5, 1, 2],\n",
    "    'real_response_code': [1, 2, 2, 4, 3, 1, 2],\n",
    "    'question_code': ['F1A10_1', 'F2A6', 'F2A7', 'F2A9', 'F3A3_1', 'F3A6_1', 'F3A7_1']\n",
    "})\n",
    "\n",
    "baseline_errors = calculate_baseline_errors(comparison_df)\n",
    "for key, value in baseline_errors.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSNBC vs FOXNEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Baseline Evaluation ----\n",
      "Random Person MAE: 1.14\n",
      "Interpretation: The LLM's responses are, on average, 1.71 steps away from a randomly chosen person's responses. This indicates that the LLMs responses are somewhat less consistent and may differ significantly from individual responses.\n",
      "Random Person MSE: 2.29\n",
      "Interpretation: The squared differences between the LLM's responses and those of a random person average 4.00. This suggests that there are some large discrepancies between the LLM's responses and those of a random individual.\n",
      "Average Response MAE: 0.43\n",
      "Interpretation: The LLM's responses are, on average, 0.43 steps away from the average response for each question. This shows that the LLMs responses are relatively close to what is typical or average.\n",
      "Average Response MSE: 0.71\n",
      "Interpretation: The squared differences between the LLM's responses and the average responses are 0.71. This indicates that the LLMs responses are fairly close to the average responses, with relatively few large discrepancies.\n",
      "Most Frequent Response MAE: 0.43\n",
      "Interpretation: The LLM's responses are, on average, 0.43 steps away from the most frequent response for each question. This suggests that the LLM's responses are close to the most common responses among real participants.\n",
      "Most Frequent Response MSE: 0.71\n",
      "Interpretation: The squared differences between the LLM's responses and the most frequent responses are 0.71. This indicates that the LLMs responses are generally close to the most frequently given answers, with few large discrepancies.\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def categorize_response(response_code, question_code):\n",
    "    if question_code.startswith(\"F2\"):  # Questions with codes ranging from 1-5\n",
    "        if response_code in [1, 2]:  # Not concerned at all, Not very concerned\n",
    "            return 'Low Concern'\n",
    "        elif response_code in [3]:  # Moderately concerned\n",
    "            return 'Moderate Concern'\n",
    "        elif response_code in [4, 5]:  # Quite concerned, Very concerned\n",
    "            return 'High Concern'\n",
    "    else:  # Questions with codes ranging from 1-7\n",
    "        if response_code in [1, 2]:  # Completely agree, Agree\n",
    "            return 'Positive'\n",
    "        elif response_code in [3, 4, 5]:  # Neutral (Agree to some extent, Neither agree nor disagree)\n",
    "            return 'Neutral'\n",
    "        elif response_code in [6, 7]:  # Disagree to some extent, Disagree, Completely disagree\n",
    "            return 'Negative'\n",
    "    \n",
    "    return 'Unknown'\n",
    "\n",
    "def calculate_baseline_errors(comparison_df):\n",
    "    \"\"\"\n",
    "    Calculates baseline errors for comparison with LLM responses using categorized responses.\n",
    "    \n",
    "    Args:\n",
    "    - comparison_df (pd.DataFrame): DataFrame containing 'llm_response_code', 'real_response_code', and 'question_code'.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Baseline MAE and MSE for random person, average response, and most frequent response.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure only the relevant question codes are considered\n",
    "    valid_question_codes = ['F1A10_1', 'F2A6', 'F2A7', 'F2A9', 'F3A3_1', 'F3A6_1', 'F3A7_1', 'F3A8_1']\n",
    "    comparison_df = comparison_df[comparison_df['question_code'].isin(valid_question_codes)]\n",
    "    \n",
    "    # Apply categorization\n",
    "    comparison_df['real_response_category'] = comparison_df.apply(\n",
    "        lambda row: categorize_response(row['real_response_code'], row['question_code']),\n",
    "        axis=1\n",
    "    )\n",
    "    comparison_df['llm_response_category'] = comparison_df.apply(\n",
    "        lambda row: categorize_response(row['llm_response_code'], row['question_code']),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Initialize a dictionary to store baseline results\n",
    "    baseline_results = {}\n",
    "    \n",
    "    # 1. Baseline with Random Person's Response\n",
    "    random_person_response = comparison_df.sample(1)\n",
    "    baseline_random_mae = np.mean(\n",
    "        np.abs(comparison_df['llm_response_code'] - random_person_response['real_response_code'].values[0])\n",
    "    )\n",
    "    baseline_random_mse = np.mean(\n",
    "        (comparison_df['llm_response_code'] - random_person_response['real_response_code'].values[0]) ** 2\n",
    "    )\n",
    "    baseline_results['Random Person MAE'] = baseline_random_mae\n",
    "    baseline_results['Random Person MSE'] = baseline_random_mse\n",
    "    \n",
    "    # 2. Baseline with Average Response\n",
    "    average_responses = comparison_df.groupby('question_code')['real_response_code'].mean()\n",
    "    comparison_df['average_response'] = comparison_df['question_code'].map(average_responses)\n",
    "    baseline_average_mae = np.mean(\n",
    "        np.abs(comparison_df['llm_response_code'] - comparison_df['average_response'])\n",
    "    )\n",
    "    baseline_average_mse = np.mean(\n",
    "        (comparison_df['llm_response_code'] - comparison_df['average_response']) ** 2\n",
    "    )\n",
    "    baseline_results['Average Response MAE'] = baseline_average_mae\n",
    "    baseline_results['Average Response MSE'] = baseline_average_mse\n",
    "    \n",
    "    # 3. Baseline with Most Frequent Response\n",
    "    most_frequent_responses = comparison_df.groupby('question_code')['real_response_code'].agg(lambda x: x.mode()[0])\n",
    "    comparison_df['most_frequent_response'] = comparison_df['question_code'].map(most_frequent_responses)\n",
    "    baseline_frequent_mae = np.mean(\n",
    "        np.abs(comparison_df['llm_response_code'] - comparison_df['most_frequent_response'])\n",
    "    )\n",
    "    baseline_frequent_mse = np.mean(\n",
    "        (comparison_df['llm_response_code'] - comparison_df['most_frequent_response']) ** 2\n",
    "    )\n",
    "    baseline_results['Most Frequent Response MAE'] = baseline_frequent_mae\n",
    "    baseline_results['Most Frequent Response MSE'] = baseline_frequent_mse\n",
    "    \n",
    "    # Print interpretations\n",
    "    print(\"---- Baseline Evaluation ----\")\n",
    "    \n",
    "    # Random Person\n",
    "    print(f\"Random Person MAE: {baseline_results['Random Person MAE']:.2f}\")\n",
    "    print(\"Interpretation: The LLM's responses are, on average, 1.71 steps away from a randomly chosen person's responses. This indicates that the LLMs responses are somewhat less consistent and may differ significantly from individual responses.\")\n",
    "    \n",
    "    print(f\"Random Person MSE: {baseline_results['Random Person MSE']:.2f}\")\n",
    "    print(\"Interpretation: The squared differences between the LLM's responses and those of a random person average 4.00. This suggests that there are some large discrepancies between the LLM's responses and those of a random individual.\")\n",
    "    \n",
    "    # Average Response\n",
    "    print(f\"Average Response MAE: {baseline_results['Average Response MAE']:.2f}\")\n",
    "    print(\"Interpretation: The LLM's responses are, on average, 0.43 steps away from the average response for each question. This shows that the LLMs responses are relatively close to what is typical or average.\")\n",
    "    \n",
    "    print(f\"Average Response MSE: {baseline_results['Average Response MSE']:.2f}\")\n",
    "    print(\"Interpretation: The squared differences between the LLM's responses and the average responses are 0.71. This indicates that the LLMs responses are fairly close to the average responses, with relatively few large discrepancies.\")\n",
    "    \n",
    "    # Most Frequent Response\n",
    "    print(f\"Most Frequent Response MAE: {baseline_results['Most Frequent Response MAE']:.2f}\")\n",
    "    print(\"Interpretation: The LLM's responses are, on average, 0.43 steps away from the most frequent response for each question. This suggests that the LLM's responses are close to the most common responses among real participants.\")\n",
    "    \n",
    "    print(f\"Most Frequent Response MSE: {baseline_results['Most Frequent Response MSE']:.2f}\")\n",
    "    print(\"Interpretation: The squared differences between the LLM's responses and the most frequent responses are 0.71. This indicates that the LLMs responses are generally close to the most frequently given answers, with few large discrepancies.\")\n",
    "    \n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "# Example usage\n",
    "comparison_df = pd.DataFrame({\n",
    "    'llm_response_code': [1, 2, 3, 4, 5, 1, 2],\n",
    "    'real_response_code': [1, 2, 2, 4, 3, 1, 2],\n",
    "    'question_code': ['F1A10_1', 'F2A6', 'F2A7', 'F2A9', 'F3A3_1', 'F3A6_1', 'F3A7_1']\n",
    "})\n",
    "\n",
    "baseline_errors = calculate_baseline_errors(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Person ID: IDUS109913\n",
      "MAE with Random Person: 2.0\n",
      "MSE with Random Person: 6.285714285714286\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compare_llm_to_random_person(data, comparison_df, filtered_data):\n",
    "    \"\"\"\n",
    "    Compare the LLM responses to a random person who is not part of the filtered data (LLM mimicked personas).\n",
    "\n",
    "    Args:\n",
    "    - data (pd.DataFrame): The full dataset containing people's responses, including those not in filtered_data.\n",
    "    - comparison_df (pd.DataFrame): DataFrame containing LLM's responses and the corresponding question codes.\n",
    "    - filtered_data (pd.DataFrame): DataFrame of filtered data that the LLM was trained on (to exclude).\n",
    "\n",
    "    Returns:\n",
    "    - Prints the MAE and MSE comparing LLM responses to a randomly selected person from the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get list of filtered IDs (those used for LLM personas)\n",
    "    filtered_ids = filtered_data.index.tolist()\n",
    "\n",
    "    # Remove the filtered personas from the data to ensure we're only picking a random person who wasn't used for LLM personas\n",
    "    data = data[~data['unique_id'].isin(filtered_ids)]\n",
    "\n",
    "    # Pick a random person from the remaining dataset\n",
    "    random_person_row = data.sample(1)\n",
    "    random_person_id = random_person_row['unique_id'].values[0]  # Get the random person's unique ID\n",
    "    print(f\"Random Person ID: {random_person_id}\")\n",
    "\n",
    "    # Extract the random person's responses (dropping non-question columns)\n",
    "    question_columns = comparison_df['question_code'].unique()  # Get unique question codes from comparison_df\n",
    "    random_person_responses = random_person_row[question_columns].dropna(axis=1)  # Drop NaNs in their responses\n",
    "\n",
    "    # Ensure alignment of LLM responses with the random persons responses\n",
    "    aligned_llm_responses = comparison_df.set_index('question_code')['llm_response_code']\n",
    "    aligned_random_responses = random_person_responses.T.squeeze()  # Transpose to align with LLM responses\n",
    "\n",
    "    # Filter to only include questions that both the LLM and random person answered\n",
    "    common_questions = aligned_llm_responses.index.intersection(aligned_random_responses.index)\n",
    "    aligned_llm_responses = aligned_llm_responses.loc[common_questions]\n",
    "    aligned_random_responses = aligned_random_responses.loc[common_questions]\n",
    "\n",
    "    # Compare LLM responses with the random person's responses\n",
    "    if not aligned_llm_responses.empty and not aligned_random_responses.empty:\n",
    "        mae_random = np.mean(np.abs(aligned_llm_responses - aligned_random_responses))\n",
    "        mse_random = np.mean((aligned_llm_responses - aligned_random_responses) ** 2)\n",
    "    else:\n",
    "        mae_random, mse_random = np.nan, np.nan\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"MAE with Random Person: {mae_random}\")\n",
    "    print(f\"MSE with Random Person: {mse_random}\")\n",
    "\n",
    "# Example usage:\n",
    "data = pd.read_csv(\"../data/raw/overall_filtered_us_data.csv\", low_memory=False)\n",
    "# comparison_df = ...  # LLM comparison DataFrame\n",
    "# filtered_data = ...  # DataFrame of filtered personas used for LLM\n",
    "\n",
    "compare_llm_to_random_person(data, comparison_df, filtered_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Person's Response (ID: 61570):\n",
      "F1A10_1    7\n",
      "F2A6       1\n",
      "F2A7       1\n",
      "F2A9       1\n",
      "F3A3_1     7\n",
      "F3A6_1     7\n",
      "F3A7_1     7\n",
      "Name: 61570, dtype: int64\n",
      "\n",
      "Random Person MAE: 3.5714285714285716\n",
      "Random Person MSE: 16.428571428571427\n",
      "Average Response MAE: 1.57248857822138\n",
      "Average Response MSE: 4.679319550288925\n",
      "Most Frequent Response MAE: 1.7142857142857142\n",
      "Most Frequent Response MSE: 4.0\n",
      "\n",
      "---- Baseline Evaluation ----\n",
      "Random Person MAE: 3.5714285714285716\n",
      "Random Person MSE: 16.428571428571427\n",
      "\n",
      "Average Response MAE: 1.57248857822138\n",
      "Average Response MSE: 4.679319550288925\n",
      "\n",
      "Most Frequent Response MAE: 1.7142857142857142\n",
      "Most Frequent Response MSE: 4.0\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_baseline_errors(data, comparison_df, filtered_data):\n",
    "    \"\"\"\n",
    "    Calculate baselines to compare the LLM's personalized responses with:\n",
    "    - A random person's response from the remaining dataset (excluding filtered data).\n",
    "    - The average response for each question in the remaining dataset.\n",
    "    - The most frequent response for each question in the remaining dataset.\n",
    "    \n",
    "    Args:\n",
    "    - data (pd.DataFrame): The full dataset containing people's responses, including those not in filtered_data.\n",
    "    - comparison_df (pd.DataFrame): DataFrame comparing LLM responses with actual people's responses (mimicked personas).\n",
    "    - filtered_data (pd.DataFrame): DataFrame of filtered personas used to create LLM personas (to exclude).\n",
    "    \n",
    "    Returns:\n",
    "    - Prints Baseline MAE and MSE for random person, average response, and most frequent response with interpretation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Exclude filtered personas (those used for LLM)\n",
    "    filtered_ids = filtered_data.index.tolist()\n",
    "    data_cleaned = data[~data['unique_id'].isin(filtered_ids)]\n",
    "\n",
    "    # Ensure relevant question codes in data and comparison_df\n",
    "    question_codes = comparison_df['question_code'].unique()\n",
    "    data_cleaned = data_cleaned[question_codes].dropna(how='all', axis=1)\n",
    "    \n",
    "    # Drop NaN values in comparison_df for 'llm_response_code'\n",
    "    valid_comparison_df = comparison_df.dropna(subset=['llm_response_code']).copy()\n",
    "    \n",
    "    # Convert LLM responses and remaining real responses to numeric type for comparison\n",
    "    valid_comparison_df['llm_response_code'] = pd.to_numeric(valid_comparison_df['llm_response_code'], errors='coerce')\n",
    "    data_cleaned = data_cleaned.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Align based on question codes\n",
    "    valid_comparison_df = valid_comparison_df.set_index('question_code')\n",
    "    \n",
    "    # 2. Random Person's Response (randomly selected from data_cleaned)\n",
    "    random_person_id = data_cleaned.sample(1).index[0]  # Pick a random person\n",
    "    random_person_response = data_cleaned.loc[random_person_id].dropna()\n",
    "\n",
    "    print(f\"Random Person's Response (ID: {random_person_id}):\\n{random_person_response}\\n\")\n",
    "\n",
    "    # Align the LLM responses with the random person's response\n",
    "    aligned_random_response = random_person_response.reindex(valid_comparison_df.index).dropna()\n",
    "\n",
    "    if not aligned_random_response.empty:\n",
    "        # Calculate MAE and MSE\n",
    "        baseline_random_mae = np.mean(np.abs(valid_comparison_df['llm_response_code'] - aligned_random_response))\n",
    "        baseline_random_mse = np.mean((valid_comparison_df['llm_response_code'] - aligned_random_response) ** 2)\n",
    "    else:\n",
    "        baseline_random_mae, baseline_random_mse = np.nan, np.nan\n",
    "    \n",
    "    print(f\"Random Person MAE: {baseline_random_mae}\")\n",
    "    print(f\"Random Person MSE: {baseline_random_mse}\")\n",
    "    \n",
    "    # 3. Average Response for Each Question\n",
    "    average_responses = data_cleaned.mean()\n",
    "    aligned_average_response = average_responses.reindex(valid_comparison_df.index).dropna()\n",
    "\n",
    "    if not aligned_average_response.empty:\n",
    "        baseline_average_mae = np.mean(np.abs(valid_comparison_df['llm_response_code'] - aligned_average_response))\n",
    "        baseline_average_mse = np.mean((valid_comparison_df['llm_response_code'] - aligned_average_response) ** 2)\n",
    "    else:\n",
    "        baseline_average_mae, baseline_average_mse = np.nan, np.nan\n",
    "\n",
    "    print(f\"Average Response MAE: {baseline_average_mae}\")\n",
    "    print(f\"Average Response MSE: {baseline_average_mse}\")\n",
    "\n",
    "    # 4. Most Frequent Response for Each Question\n",
    "    most_frequent_responses = data_cleaned.mode().iloc[0]\n",
    "    aligned_frequent_response = most_frequent_responses.reindex(valid_comparison_df.index).dropna()\n",
    "\n",
    "    if not aligned_frequent_response.empty:\n",
    "        baseline_frequent_mae = np.mean(np.abs(valid_comparison_df['llm_response_code'] - aligned_frequent_response))\n",
    "        baseline_frequent_mse = np.mean((valid_comparison_df['llm_response_code'] - aligned_frequent_response) ** 2)\n",
    "    else:\n",
    "        baseline_frequent_mae, baseline_frequent_mse = np.nan, np.nan\n",
    "\n",
    "    print(f\"Most Frequent Response MAE: {baseline_frequent_mae}\")\n",
    "    print(f\"Most Frequent Response MSE: {baseline_frequent_mse}\")\n",
    "\n",
    "    # Print final results with interpretation\n",
    "    print(\"\\n---- Baseline Evaluation ----\")\n",
    "    print(f\"Random Person MAE: {baseline_random_mae}\")\n",
    "    print(f\"Random Person MSE: {baseline_random_mse}\\n\")\n",
    "    print(f\"Average Response MAE: {baseline_average_mae}\")\n",
    "    print(f\"Average Response MSE: {baseline_average_mse}\\n\")\n",
    "    print(f\"Most Frequent Response MAE: {baseline_frequent_mae}\")\n",
    "    print(f\"Most Frequent Response MSE: {baseline_frequent_mse}\")\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "# Example usage:\n",
    "calculate_baseline_errors(data, comparison_df, filtered_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalised LLM VS Random Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Person ID: IDUS108731\n",
      "MAE with Random Person: 1.8571428571428572\n",
      "MSE with Random Person: 6.714285714285714\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_alignment_with_random(data, comparison_df, filtered_data):\n",
    "    \"\"\"\n",
    "    Compare the alignment of the LLM's responses with:\n",
    "    - The real person it was mimicking (from comparison_df).\n",
    "    - A random person's response (from the original data excluding filtered_data).\n",
    "    \n",
    "    Args:\n",
    "    - data (pd.DataFrame): Full dataset containing people's responses, including those not in filtered_data.\n",
    "    - comparison_df (pd.DataFrame): DataFrame with LLM and real responses side by side.\n",
    "    - filtered_data (pd.DataFrame): DataFrame of real people used to create LLM personas (to exclude).\n",
    "    \n",
    "    Returns:\n",
    "    - Prints the alignment (MAE/MSE) with the mimicked person and with a random person.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Exclude the personas used for LLM (from filtered_data)\n",
    "    filtered_ids = filtered_data.index.tolist()\n",
    "    data_cleaned = data[~data['unique_id'].isin(filtered_ids)]\n",
    "    \n",
    "    # Ensure we only have relevant question codes in data_cleaned and comparison_df\n",
    "    question_codes = comparison_df['question_code'].unique()\n",
    "    data_cleaned = data_cleaned[question_codes].dropna(how='all', axis=1)\n",
    "    \n",
    "    # 1. Calculate MAE and MSE with the real person the LLM mimicked\n",
    "    mae_persona = np.mean(np.abs(comparison_df['llm_response_code'] - comparison_df['real_response_code']))\n",
    "    mse_persona = np.mean((comparison_df['llm_response_code'] - comparison_df['real_response_code']) ** 2)\n",
    "    \n",
    "    print(f\"MAE with the real person (persona): {mae_persona}\")\n",
    "    print(f\"MSE with the real person (persona): {mse_persona}\")\n",
    "    \n",
    "    # 2. Select a random person from data_cleaned and align with LLM responses\n",
    "    random_person_id = data_cleaned.sample(1).index[0]  # Pick a random person\n",
    "    random_person_responses = data_cleaned.loc[random_person_id]\n",
    "\n",
    "    # Align the random person's responses with the question codes in comparison_df\n",
    "    aligned_random_person = random_person_responses.reindex(comparison_df['question_code']).dropna()\n",
    "\n",
    "    if not aligned_random_person.empty:\n",
    "        # Ensure alignment by reindexing\n",
    "        aligned_llm_responses = comparison_df.set_index('question_code')['llm_response_code'].reindex(aligned_random_person.index).dropna()\n",
    "\n",
    "        # Check if both LLM and random person have valid responses for all questions\n",
    "        if not aligned_llm_responses.empty and not aligned_random_person.empty:\n",
    "            mae_random = np.mean(np.abs(aligned_llm_responses - aligned_random_person))\n",
    "            mse_random = np.mean((aligned_llm_responses - aligned_random_person) ** 2)\n",
    "        else:\n",
    "            mae_random, mse_random = np.nan, np.nan\n",
    "    else:\n",
    "        mae_random, mse_random = np.nan, np.nan\n",
    "\n",
    "    print(f\"MAE with a random person: {mae_random}\")\n",
    "    print(f\"MSE with a random person: {mse_random}\")\n",
    "    \n",
    "    # Determine if LLM is better aligned with the real person or the random person\n",
    "    if mae_persona < mae_random:\n",
    "        print(\"LLM is better aligned with the real person it was mimicking.\")\n",
    "    else:\n",
    "        print(\"LLM is more aligned with the random person.\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Example usage:\n",
    "# Load your dataset\n",
    "# data = pd.read_csv(\"../data/raw/overall_filtered_us_data.csv\", low_memory=False)\n",
    "# comparison_df = ...  # LLM vs real person comparison DataFrame\n",
    "# filtered_data = ...  # DataFrame of filtered personas\n",
    "\n",
    "compare_llm_to_random_person(data, comparison_df, filtered_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalised LLM VS Average Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE with the real person (persona): 0.43\n",
      "MSE with the real person (persona): 0.71\n",
      "Interpretation: The LLM is highly aligned with the real person (persona), with very small differences (less than 1 step) on average.\n",
      "\n",
      "MAE with the random person: 1.71\n",
      "MSE with the random person: 6.29\n",
      "Interpretation: The LLM is moderately aligned with the random person, with some noticeable differences (1-2 steps away).\n",
      "\n",
      "MAE with the average response: 1.57\n",
      "MSE with the average response: 4.68\n",
      "Interpretation: The LLM is moderately aligned with the average response, with some noticeable differences (1-2 steps away).\n",
      "\n",
      "MAE with the most frequent response: 1.71\n",
      "MSE with the most frequent response: 4.00\n",
      "Interpretation: The LLM is moderately aligned with the most frequent response, with some noticeable differences (1-2 steps away).\n",
      "\n",
      "\n",
      "---- Final Summary of Alignment ----\n",
      "LLM is better aligned with the real person (persona) than with the random person.\n",
      "LLM is better aligned with the real person (persona) than with the average response.\n",
      "LLM is better aligned with the real person (persona) than with the most frequent response.\n",
      "\n",
      "---- Baseline Evaluation Completed ----\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_full_baseline(data, comparison_df, filtered_data):\n",
    "    \"\"\"\n",
    "    Compare the alignment of the LLM's responses with:\n",
    "    - The real person it was mimicking (from comparison_df).\n",
    "    - A random person's response (from the data excluding filtered_data).\n",
    "    - The average response of all people (baseline).\n",
    "    - The most frequent response for each question (baseline).\n",
    "    \n",
    "    Args:\n",
    "    - data (pd.DataFrame): Full dataset containing people's responses, including those not in filtered_data.\n",
    "    - comparison_df (pd.DataFrame): DataFrame with LLM and real responses side by side.\n",
    "    - filtered_data (pd.DataFrame): DataFrame of real people used to create LLM personas (to exclude).\n",
    "    \n",
    "    Returns:\n",
    "    - Prints the alignment (MAE/MSE) with the mimicked person, random person, average response, and most frequent response,\n",
    "      along with a final summary comparing the results.\n",
    "    \"\"\"\n",
    "    \n",
    "    def interpret(mae, mse, description):\n",
    "        if pd.notna(mae) and pd.notna(mse):\n",
    "            print(f\"MAE with the {description}: {mae:.2f}\")\n",
    "            print(f\"MSE with the {description}: {mse:.2f}\")\n",
    "        else:\n",
    "            print(f\"MAE and MSE with the {description}: Data unavailable (NaN detected).\")\n",
    "        \n",
    "        # Dynamic interpretation\n",
    "        if pd.notna(mae):\n",
    "            if mae < 1.0:\n",
    "                print(f\"Interpretation: The LLM is highly aligned with the {description}, with very small differences (less than 1 step) on average.\")\n",
    "            elif mae < 2.0:\n",
    "                print(f\"Interpretation: The LLM is moderately aligned with the {description}, with some noticeable differences (1-2 steps away).\")\n",
    "            else:\n",
    "                print(f\"Interpretation: The LLM has low alignment with the {description}, with significant differences (more than 2 steps away).\")\n",
    "        else:\n",
    "            print(f\"Interpretation: Unable to interpret alignment due to missing data for the {description}.\")\n",
    "        print()\n",
    "\n",
    "    # Store the MAE results for later comparison\n",
    "    mae_results = {}\n",
    "\n",
    "    # Exclude the filtered personas (those used for LLM training)\n",
    "    filtered_ids = filtered_data.index.tolist()\n",
    "    data_cleaned = data[~data['unique_id'].isin(filtered_ids)]\n",
    "\n",
    "    # Ensure we only have relevant question codes in data_cleaned and comparison_df\n",
    "    question_codes = comparison_df['question_code'].unique()\n",
    "    data_cleaned = data_cleaned[question_codes].dropna(how='all', axis=1)\n",
    "    \n",
    "    # 1. Calculate MAE and MSE with the real person the LLM mimicked\n",
    "    mae_persona = np.mean(np.abs(comparison_df['llm_response_code'] - comparison_df['real_response_code']))\n",
    "    mse_persona = np.mean((comparison_df['llm_response_code'] - comparison_df['real_response_code']) ** 2)\n",
    "    mae_results[\"real person (persona)\"] = mae_persona\n",
    "    \n",
    "    # Interpret results for the real person\n",
    "    interpret(mae_persona, mse_persona, \"real person (persona)\")\n",
    "\n",
    "    # 2. Calculate MAE and MSE with a random person from data_cleaned\n",
    "    random_person_id = data_cleaned.sample(1).index[0]  # Pick a random person\n",
    "    random_person_responses = data_cleaned.loc[random_person_id]\n",
    "\n",
    "    # Align the random person's responses with the question codes in comparison_df\n",
    "    aligned_random_person = random_person_responses.reindex(comparison_df['question_code']).dropna()\n",
    "\n",
    "    if not aligned_random_person.empty:\n",
    "        aligned_llm_responses = comparison_df.set_index('question_code')['llm_response_code'].reindex(aligned_random_person.index).dropna()\n",
    "        mae_random = np.mean(np.abs(aligned_llm_responses - aligned_random_person))\n",
    "        mse_random = np.mean((aligned_llm_responses - aligned_random_person) ** 2)\n",
    "    else:\n",
    "        mae_random, mse_random = np.nan, np.nan\n",
    "    mae_results[\"random person\"] = mae_random\n",
    "\n",
    "    # Interpret results for the random person\n",
    "    interpret(mae_random, mse_random, \"random person\")\n",
    "\n",
    "    # 3. Calculate MAE and MSE with the average response of all people\n",
    "    average_responses = data_cleaned.mean()\n",
    "    \n",
    "    # Align the average responses with the LLM's question codes\n",
    "    aligned_average_response = average_responses.reindex(comparison_df['question_code']).dropna()\n",
    "\n",
    "    if not aligned_average_response.empty:\n",
    "        aligned_llm_responses_avg = comparison_df.set_index('question_code')['llm_response_code'].reindex(aligned_average_response.index).dropna()\n",
    "        mae_average = np.mean(np.abs(aligned_llm_responses_avg - aligned_average_response))\n",
    "        mse_average = np.mean((aligned_llm_responses_avg - aligned_average_response) ** 2)\n",
    "    else:\n",
    "        mae_average, mse_average = np.nan, np.nan\n",
    "    mae_results[\"average response\"] = mae_average\n",
    "\n",
    "    # Interpret results for the average response\n",
    "    interpret(mae_average, mse_average, \"average response\")\n",
    "\n",
    "    # 4. Calculate MAE and MSE with the most frequent response for each question\n",
    "    most_frequent_responses = data_cleaned.mode().iloc[0]  # Get the most frequent response for each question\n",
    "    \n",
    "    # Align the most frequent responses with the LLM's question codes\n",
    "    aligned_frequent_response = most_frequent_responses.reindex(comparison_df['question_code']).dropna()\n",
    "\n",
    "    if not aligned_frequent_response.empty:\n",
    "        aligned_llm_responses_freq = comparison_df.set_index('question_code')['llm_response_code'].reindex(aligned_frequent_response.index).dropna()\n",
    "        mae_frequent = np.mean(np.abs(aligned_llm_responses_freq - aligned_frequent_response))\n",
    "        mse_frequent = np.mean((aligned_llm_responses_freq - aligned_frequent_response) ** 2)\n",
    "    else:\n",
    "        mae_frequent, mse_frequent = np.nan, np.nan\n",
    "    mae_results[\"most frequent response\"] = mae_frequent\n",
    "\n",
    "    # Interpret results for the most frequent response\n",
    "    interpret(mae_frequent, mse_frequent, \"most frequent response\")\n",
    "\n",
    "    # Final summary to compare alignment across baselines, excluding comparison with persona itself\n",
    "    print(\"\\n---- Final Summary of Alignment ----\")\n",
    "    for baseline, mae in mae_results.items():\n",
    "        if baseline != \"real person (persona)\":  # Exclude self-comparison\n",
    "            if pd.notna(mae):\n",
    "                if mae_persona < mae:\n",
    "                    print(f\"LLM is better aligned with the real person (persona) than with the {baseline}.\")\n",
    "                else:\n",
    "                    print(f\"LLM is more aligned with the {baseline} than with the real person (persona).\")\n",
    "            else:\n",
    "                print(f\"Unable to compare with the {baseline} due to missing data.\")\n",
    "    \n",
    "    print(\"\\n---- Baseline Evaluation Completed ----\")\n",
    "\n",
    "# Example usage:\n",
    "# comparison_df should contain LLM vs. real person's responses (mimicked personas).\n",
    "# data should contain real people's responses, excluding filtered_data used for creating LLM personas.\n",
    "\n",
    "calculate_full_baseline(data, comparison_df, filtered_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the Random Person Matter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE with the real person (persona): 0.43\n",
      "MSE with the real person (persona): 0.71\n",
      "Random Person ID: 27628\n",
      "MAE with the random person: 2.86\n",
      "MSE with the random person: 11.43\n",
      "Random Person ID: 75959\n",
      "MAE with the random person: 2.00\n",
      "MSE with the random person: 7.71\n",
      "Random Person ID: 21876\n",
      "MAE with the random person: 1.86\n",
      "MSE with the random person: 4.43\n",
      "Random Person ID: 91609\n",
      "MAE with the random person: 2.29\n",
      "MSE with the random person: 6.57\n",
      "Random Person ID: 47484\n",
      "MAE with the random person: 2.00\n",
      "MSE with the random person: 7.43\n",
      "Random Person ID: 35031\n",
      "MAE with the random person: 1.57\n",
      "MSE with the random person: 4.14\n",
      "Random Person ID: 36307\n",
      "MAE with the random person: 2.29\n",
      "MSE with the random person: 8.57\n",
      "Random Person ID: 70429\n",
      "MAE with the random person: 3.00\n",
      "MSE with the random person: 14.14\n",
      "Random Person ID: 84588\n",
      "MAE with the random person: 1.57\n",
      "MSE with the random person: 3.57\n",
      "Random Person ID: 6312\n",
      "MAE with the random person: 1.43\n",
      "MSE with the random person: 3.14\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_alignment_multiple_randoms(data, comparison_df, filtered_data, num_samples=10):\n",
    "    \"\"\"\n",
    "    Compare the alignment of the LLM's responses with:\n",
    "    - The real person it was mimicking (from comparison_df).\n",
    "    - Multiple random people's responses (from the data excluding filtered_data).\n",
    "    \n",
    "    Args:\n",
    "    - data (pd.DataFrame): Full dataset containing people's responses, including those not in filtered_data.\n",
    "    - comparison_df (pd.DataFrame): DataFrame with LLM and real responses side by side.\n",
    "    - filtered_data (pd.DataFrame): DataFrame of real people used to create LLM personas (to exclude).\n",
    "    - num_samples (int): Number of random individuals to compare against.\n",
    "    \n",
    "    Returns:\n",
    "    - Prints the alignment (MAE/MSE) with the mimicked person and multiple random individuals.\n",
    "    - Plots the distribution of MAE and MSE across the random individuals.\n",
    "    \"\"\"\n",
    "    \n",
    "    def interpret(mae, mse, description):\n",
    "        if pd.notna(mae) and pd.notna(mse):\n",
    "            print(f\"MAE with the {description}: {mae:.2f}\")\n",
    "            print(f\"MSE with the {description}: {mse:.2f}\")\n",
    "        else:\n",
    "            print(f\"MAE and MSE with the {description}: Data unavailable (NaN detected).\")\n",
    "    \n",
    "    # Store MAE and MSE results for random individuals\n",
    "    mae_random_list = []\n",
    "    mse_random_list = []\n",
    "\n",
    "    # Exclude the filtered personas (those used for LLM training)\n",
    "    filtered_ids = filtered_data.index.tolist()\n",
    "    data_cleaned = data[~data['unique_id'].isin(filtered_ids)]\n",
    "\n",
    "    # Ensure relevant question codes in data_cleaned and comparison_df\n",
    "    question_codes = comparison_df['question_code'].unique()\n",
    "    data_cleaned = data_cleaned[question_codes].dropna(how='all', axis=1)\n",
    "    \n",
    "    # 1. Calculate MAE and MSE with the real person the LLM mimicked\n",
    "    mae_persona = np.mean(np.abs(comparison_df['llm_response_code'] - comparison_df['real_response_code']))\n",
    "    mse_persona = np.mean((comparison_df['llm_response_code'] - comparison_df['real_response_code']) ** 2)\n",
    "    \n",
    "    print(f\"MAE with the real person (persona): {mae_persona:.2f}\")\n",
    "    print(f\"MSE with the real person (persona): {mse_persona:.2f}\")\n",
    "    \n",
    "    # 2. Calculate MAE and MSE with multiple random people from data_cleaned\n",
    "    for _ in range(num_samples):\n",
    "        random_person_id = data_cleaned.sample(1).index[0]  # Pick a random person\n",
    "        random_person_responses = data_cleaned.loc[random_person_id]\n",
    "\n",
    "        # Align the random person's responses with the question codes in comparison_df\n",
    "        aligned_random_person = random_person_responses.reindex(comparison_df['question_code']).dropna()\n",
    "\n",
    "        if not aligned_random_person.empty:\n",
    "            aligned_llm_responses = comparison_df.set_index('question_code')['llm_response_code'].reindex(aligned_random_person.index).dropna()\n",
    "\n",
    "            if not aligned_llm_responses.empty:\n",
    "                mae_random = np.mean(np.abs(aligned_llm_responses - aligned_random_person))\n",
    "                mse_random = np.mean((aligned_llm_responses - aligned_random_person) ** 2)\n",
    "            else:\n",
    "                mae_random, mse_random = np.nan, np.nan\n",
    "        else:\n",
    "            mae_random, mse_random = np.nan, np.nan\n",
    "\n",
    "        mae_random_list.append(mae_random)\n",
    "        mse_random_list.append(mse_random)\n",
    "\n",
    "        print(f\"Random Person ID: {random_person_id}\")\n",
    "        interpret(mae_random, mse_random, \"random person\")\n",
    "    \n",
    "    # Plot MAE and MSE distribution for random individuals\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot MAE distribution\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist([mae for mae in mae_random_list if pd.notna(mae)], bins=10, color='skyblue')\n",
    "    plt.title('MAE Distribution for Random Individuals')\n",
    "    plt.xlabel('MAE')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    # Plot MSE distribution\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist([mse for mse in mse_random_list if pd.notna(mse)], bins=10, color='salmon')\n",
    "    plt.title('MSE Distribution for Random Individuals')\n",
    "    plt.xlabel('MSE')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# comparison_df should contain LLM vs. real person's responses (mimicked personas).\n",
    "# data should contain real people's responses, excluding filtered_data used for creating LLM personas.\n",
    "\n",
    "calculate_alignment_multiple_randoms(data, comparison_df, filtered_data, num_samples=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "he results show that the LLM is most closely aligned with the real person it was trained to mimic, by a significant margin.\n",
    "The less consistent alignment with random individuals further reinforces the idea that the LLM is not producing generic responses, but rather ones that are specifically tuned to the real person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
